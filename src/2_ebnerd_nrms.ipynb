{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "see paper: https://wuch15.github.io/paper/EMNLP2019-NRMS.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel # huggingface transformers\n",
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "import polars as pl\n",
    "\n",
    "\"\"\"\n",
    "preprocessing\n",
    "\"\"\"\n",
    "\n",
    "from ebrec.utils._constants import ( # column names as constants\n",
    "    DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "    DEFAULT_CLICKED_ARTICLES_COL,\n",
    "    DEFAULT_INVIEW_ARTICLES_COL,\n",
    "    DEFAULT_IMPRESSION_ID_COL,\n",
    "    DEFAULT_SUBTITLE_COL,\n",
    "    DEFAULT_LABELS_COL,\n",
    "    DEFAULT_TITLE_COL,\n",
    "    DEFAULT_USER_COL,\n",
    ")\n",
    "from ebrec.utils._behaviors import (\n",
    "    create_binary_labels_column, # add a binary labels column to the dataframe\n",
    "    sampling_strategy_wu2019, # sampling strategy from NPA paper\n",
    "    add_known_user_column, # add a column to the dataframe saying whether user has been seen before\n",
    "    add_prediction_scores, # add a column to the dataframe with the prediction scores\n",
    "    truncate_history, # sort by timestamp and truncate the history to the last n articles\n",
    ")\n",
    "from ebrec.utils._articles import convert_text2encoding_with_transformers # tokenize text with transformers\n",
    "from ebrec.utils._polars import concat_str_columns, slice_join_dataframes # merge two columns, merge two dataframes\n",
    "from ebrec.utils._articles import create_article_id_to_value_mapping # add row id (because it isn't the default in polars)\n",
    "from ebrec.utils._nlp import get_transformers_word_embeddings # turn tokens into word embeddings\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "nrms model\n",
    "\"\"\"\n",
    "\n",
    "from ebrec.models.newsrec.dataloader import NRMSDataLoader # load news rec data\n",
    "from ebrec.models.newsrec.model_config import hparams_nrms # class to globally store hyperparameters as constants\n",
    "from ebrec.models.newsrec import NRMSModel # the model itself"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "data_base = Path(os.getcwd()).parent / \"data-merged\" / \"merged\"\n",
    "# train_val_base = data_base / \"1-ebnerd_demo_(20MB)\"\n",
    "train_val_base = data_base / \"2-ebnerd_small_(80MB)\"\n",
    "# train_val_base = data_base / \"3-ebnerd_large_(3.0GB)\"\n",
    "test_base = data_base / \"5-ebnerd_testset_(1.5GB)\"\n",
    "assert train_val_base.exists() and test_base.exists()\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "load user history\n",
    "\"\"\"\n",
    "\n",
    "train_behaviors = pl.scan_parquet(train_val_base / \"train\" / \"behaviors.parquet\")\n",
    "train_history = pl.scan_parquet(train_val_base / \"train\" / \"history.parquet\")\n",
    "\n",
    "val_behavior = pl.scan_parquet(train_val_base / \"validation\" / \"behaviors.parquet\")\n",
    "val_history = pl.scan_parquet(train_val_base / \"validation\" / \"history.parquet\")\n",
    "\n",
    "test_behavior = pl.scan_parquet(test_base / \"test\" / \"behaviors.parquet\")\n",
    "test_history = pl.scan_parquet(test_base / \"test\" / \"history.parquet\")\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "load article content\n",
    "\"\"\"\n",
    "\n",
    "train_articles: pl.LazyFrame = pl.scan_parquet(train_val_base / \"articles.parquet\")\n",
    "val_articles: pl.LazyFrame = train_articles\n",
    "test_articles: pl.LazyFrame = pl.scan_parquet(test_base / \"articles.parquet\")\n",
    "\n",
    "articles_word2vec: pl.LazyFrame = pl.scan_parquet(data_base / \"7-Ekstra-Bladet-word2vec_(133MB)\" / \"document_vector.parquet\")\n",
    "articles_image_embeddings: pl.LazyFrame = pl.scan_parquet(data_base / \"8-Ekstra_Bladet_image_embeddings_(372MB)\" / \"image_embeddings.parquet\")\n",
    "articles_contrastive_vector: pl.LazyFrame = pl.scan_parquet(data_base / \"9-Ekstra-Bladet-contrastive_vector_(341MB)\" / \"contrastive_vector.parquet\")\n",
    "articles_bert_base_multilingual_cased: pl.LazyFrame = pl.scan_parquet(data_base / \"10-google-bert-base-multilingual-cased_(344MB)\" / \"bert_base_multilingual_cased.parquet\")\n",
    "articles_xlm_roberta_base: pl.LazyFrame = pl.scan_parquet(data_base / \"11-FacebookAI-xlm-roberta-base_(341MB)\" / \"xlm_roberta_base.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ebnerd_from_path(history: pl.LazyFrame, behaviors: pl.LazyFrame, history_size: int = 30) -> pl.DataFrame:\n",
    "    df_history = (\n",
    "        history\n",
    "        .select(DEFAULT_USER_COL, DEFAULT_HISTORY_ARTICLE_ID_COL)\n",
    "        .pipe(\n",
    "            truncate_history,\n",
    "            column=DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "            history_size=history_size,\n",
    "            padding_value=0,\n",
    "        )\n",
    "    )\n",
    "    df_behaviors = (\n",
    "        behaviors\n",
    "        .collect()\n",
    "        .pipe(\n",
    "            slice_join_dataframes,\n",
    "            df2=df_history.collect(),\n",
    "            on=DEFAULT_USER_COL,\n",
    "            how=\"left\",\n",
    "        )\n",
    "    )\n",
    "    return df_behaviors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate labels\n",
    "We sample a few just to get started. For testset we just make up a dummy column with 0 and 1 - this is not the true labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sueszli/.asdf/installs/python/3.11.9/lib/python3.11/site-packages/ebrec/utils/_behaviors.py:619: UserWarning: truncate_history: The history IDs expeced in ascending order\n",
      "  warnings.warn(f\"{function_name}: The history IDs expeced in ascending order\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done: train\n",
      "done: validation\n",
      "done: test\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "preprocessing: truncate user history, select subset of columns, join on behavior, sample based on Wu2019, add binary labels column\n",
    "\"\"\"\n",
    "\n",
    "COLUMNS = [\n",
    "    DEFAULT_USER_COL,\n",
    "    DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "    DEFAULT_INVIEW_ARTICLES_COL,\n",
    "    DEFAULT_CLICKED_ARTICLES_COL,\n",
    "]\n",
    "HISTORY_SIZE = 30\n",
    "N_SAMPLES = 100\n",
    "df_train = (\n",
    "    ebnerd_from_path(history=train_history, behaviors=train_behaviors, history_size=HISTORY_SIZE)\n",
    "    .select(COLUMNS)\n",
    "    .pipe(\n",
    "        sampling_strategy_wu2019,\n",
    "        npratio=4,\n",
    "        shuffle=True,\n",
    "        with_replacement=True,\n",
    "        seed=123,\n",
    "    )\n",
    "    .pipe(create_binary_labels_column)\n",
    "    .sample(n=N_SAMPLES)\n",
    ")\n",
    "print(\"done: train\")\n",
    "\n",
    "df_validation = (\n",
    "    ebnerd_from_path(history=val_history, behaviors=val_behavior, history_size=HISTORY_SIZE)\n",
    "    .select(COLUMNS)\n",
    "    .pipe(create_binary_labels_column)\n",
    "    .sample(n=N_SAMPLES)\n",
    ")\n",
    "print(\"done: validation\")\n",
    "\n",
    "df_test = (\n",
    "    ebnerd_from_path(history=test_history, behaviors=val_behavior, history_size=HISTORY_SIZE)\n",
    "    .with_columns(pl.Series(DEFAULT_CLICKED_ARTICLES_COL, [[]]))\n",
    "    .select(COLUMNS)\n",
    "    .pipe(create_binary_labels_column)\n",
    "    .sample(n=N_SAMPLES)\n",
    ")\n",
    "print(\"done: test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at the difference between Training/Validation and Testset\n",
    "Note, the testset doesn't include labels, and we have remove some of the other columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>user_id</th><th>article_id_fixed</th><th>article_ids_inview</th><th>article_ids_clicked</th><th>labels</th></tr><tr><td>u32</td><td>list[i32]</td><td>list[i64]</td><td>list[i64]</td><td>list[i8]</td></tr></thead><tbody><tr><td>689819</td><td>[9767765, 9768722, … 9770146]</td><td>[9773137, 9773137, … 9772355]</td><td>[9772635]</td><td>[0, 0, … 0]</td></tr><tr><td>2256162</td><td>[9767738, 9768708, … 9769366]</td><td>[9778902, 9778902, … 9777156]</td><td>[9777156]</td><td>[0, 0, … 1]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2, 5)\n",
       "┌─────────┬──────────────────────┬──────────────────────┬─────────────────────┬─────────────┐\n",
       "│ user_id ┆ article_id_fixed     ┆ article_ids_inview   ┆ article_ids_clicked ┆ labels      │\n",
       "│ ---     ┆ ---                  ┆ ---                  ┆ ---                 ┆ ---         │\n",
       "│ u32     ┆ list[i32]            ┆ list[i64]            ┆ list[i64]           ┆ list[i8]    │\n",
       "╞═════════╪══════════════════════╪══════════════════════╪═════════════════════╪═════════════╡\n",
       "│ 689819  ┆ [9767765, 9768722, … ┆ [9773137, 9773137, … ┆ [9772635]           ┆ [0, 0, … 0] │\n",
       "│         ┆ 9770146]             ┆ 9772355]             ┆                     ┆             │\n",
       "│ 2256162 ┆ [9767738, 9768708, … ┆ [9778902, 9778902, … ┆ [9777156]           ┆ [0, 0, … 1] │\n",
       "│         ┆ 9769366]             ┆ 9777156]             ┆                     ┆             │\n",
       "└─────────┴──────────────────────┴──────────────────────┴─────────────────────┴─────────────┘"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>user_id</th><th>article_id_fixed</th><th>article_ids_inview</th><th>article_ids_clicked</th><th>labels</th></tr><tr><td>u32</td><td>list[i32]</td><td>list[i32]</td><td>list[null]</td><td>list[i8]</td></tr></thead><tbody><tr><td>2124286</td><td>[9785019, 9787098, … 9787586]</td><td>[9781998, 9784406, … 9782836]</td><td>[]</td><td>[0, 0, … 0]</td></tr><tr><td>881917</td><td>[9790574, 9790121, … 9776147]</td><td>[9766007, 9769994, … 9769459]</td><td>[]</td><td>[0, 0, … 0]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2, 5)\n",
       "┌─────────┬──────────────────────┬──────────────────────┬─────────────────────┬─────────────┐\n",
       "│ user_id ┆ article_id_fixed     ┆ article_ids_inview   ┆ article_ids_clicked ┆ labels      │\n",
       "│ ---     ┆ ---                  ┆ ---                  ┆ ---                 ┆ ---         │\n",
       "│ u32     ┆ list[i32]            ┆ list[i32]            ┆ list[null]          ┆ list[i8]    │\n",
       "╞═════════╪══════════════════════╪══════════════════════╪═════════════════════╪═════════════╡\n",
       "│ 2124286 ┆ [9785019, 9787098, … ┆ [9781998, 9784406, … ┆ []                  ┆ [0, 0, … 0] │\n",
       "│         ┆ 9787586]             ┆ 9782836]             ┆                     ┆             │\n",
       "│ 881917  ┆ [9790574, 9790121, … ┆ [9766007, 9769994, … ┆ []                  ┆ [0, 0, … 0] │\n",
       "│         ┆ 9776147]             ┆ 9769459]             ┆                     ┆             │\n",
       "└─────────┴──────────────────────┴──────────────────────┴─────────────────────┴─────────────┘"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 21)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>article_id</th><th>title</th><th>subtitle</th><th>last_modified_time</th><th>premium</th><th>body</th><th>published_time</th><th>image_ids</th><th>article_type</th><th>url</th><th>ner_clusters</th><th>entity_groups</th><th>topics</th><th>category</th><th>subcategory</th><th>category_str</th><th>total_inviews</th><th>total_pageviews</th><th>total_read_time</th><th>sentiment_score</th><th>sentiment_label</th></tr><tr><td>i32</td><td>str</td><td>str</td><td>datetime[μs]</td><td>bool</td><td>str</td><td>datetime[μs]</td><td>list[i64]</td><td>str</td><td>str</td><td>list[str]</td><td>list[str]</td><td>list[str]</td><td>i16</td><td>list[i16]</td><td>str</td><td>i32</td><td>i32</td><td>f32</td><td>f32</td><td>str</td></tr></thead><tbody><tr><td>3001353</td><td>&quot;Natascha var i…</td><td>&quot;Politiet frygt…</td><td>2023-06-29 06:20:33</td><td>false</td><td>&quot;Sagen om den ø…</td><td>2006-08-31 08:06:45</td><td>[3150850]</td><td>&quot;article_defaul…</td><td>&quot;https://ekstra…</td><td>[]</td><td>[]</td><td>[&quot;Kriminalitet&quot;, &quot;Personfarlig kriminalitet&quot;]</td><td>140</td><td>[]</td><td>&quot;krimi&quot;</td><td>null</td><td>null</td><td>null</td><td>0.9955</td><td>&quot;Negative&quot;</td></tr><tr><td>3003065</td><td>&quot;Kun Star Wars …</td><td>&quot;Biografgængern…</td><td>2023-06-29 06:20:35</td><td>false</td><td>&quot;Vatikanet har …</td><td>2006-05-21 16:57:00</td><td>[3006712]</td><td>&quot;article_defaul…</td><td>&quot;https://ekstra…</td><td>[]</td><td>[]</td><td>[&quot;Underholdning&quot;, &quot;Film og tv&quot;, &quot;Økonomi&quot;]</td><td>414</td><td>[433, 434]</td><td>&quot;underholdning&quot;</td><td>null</td><td>null</td><td>null</td><td>0.846</td><td>&quot;Positive&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2, 21)\n",
       "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
       "│ article_i ┆ title     ┆ subtitle  ┆ last_modi ┆ … ┆ total_pag ┆ total_rea ┆ sentiment ┆ sentimen │\n",
       "│ d         ┆ ---       ┆ ---       ┆ fied_time ┆   ┆ eviews    ┆ d_time    ┆ _score    ┆ t_label  │\n",
       "│ ---       ┆ str       ┆ str       ┆ ---       ┆   ┆ ---       ┆ ---       ┆ ---       ┆ ---      │\n",
       "│ i32       ┆           ┆           ┆ datetime[ ┆   ┆ i32       ┆ f32       ┆ f32       ┆ str      │\n",
       "│           ┆           ┆           ┆ μs]       ┆   ┆           ┆           ┆           ┆          │\n",
       "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
       "│ 3001353   ┆ Natascha  ┆ Politiet  ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.9955    ┆ Negative │\n",
       "│           ┆ var ikke  ┆ frygter   ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ den       ┆ nu, at    ┆ 06:20:33  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ første    ┆ Natascha… ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 3003065   ┆ Kun Star  ┆ Biografgæ ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.846     ┆ Positive │\n",
       "│           ┆ Wars      ┆ ngerne    ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ tjente    ┆ strømmer  ┆ 06:20:35  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ mere      ┆ ind for…  ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_articles = train_articles.collect()\n",
    "df_articles.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init model using HuggingFace's tokenizer and wordembedding\n",
    "In the original implementation, they use the GloVe embeddings and tokenizer. To get going fast, we'll use a multilingual LLM from Hugging Face. \n",
    "Utilizing the tokenizer to tokenize the articles and the word-embedding to init NRMS.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sueszli/.asdf/installs/python/3.11.9/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/Users/sueszli/.asdf/installs/python/3.11.9/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "TRANSFORMER_MODEL_NAME = \"bert-base-multilingual-cased\"\n",
    "TEXT_COLUMNS_TO_USE = [DEFAULT_SUBTITLE_COL, DEFAULT_TITLE_COL]\n",
    "MAX_TITLE_LENGTH = 30\n",
    "\n",
    "# LOAD HUGGINGFACE:\n",
    "transformer_model = AutoModel.from_pretrained(TRANSFORMER_MODEL_NAME)\n",
    "transformer_tokenizer = AutoTokenizer.from_pretrained(TRANSFORMER_MODEL_NAME)\n",
    "\n",
    "# We'll init the word embeddings using the\n",
    "word2vec_embedding = get_transformers_word_embeddings(transformer_model)\n",
    "# concat columns containing strings\n",
    "df_articles, cat_cal = concat_str_columns(df_articles, columns=TEXT_COLUMNS_TO_USE)\n",
    "# convert text to tokens\n",
    "df_articles, token_col_title = convert_text2encoding_with_transformers(\n",
    "    df_articles, transformer_tokenizer, cat_cal, max_length=MAX_TITLE_LENGTH\n",
    ")\n",
    "# add row id to the dataframe (because it isn't the default in polars)\n",
    "article_mapping = create_article_id_to_value_mapping(\n",
    "    df=df_articles, value_col=token_col_title\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initiate the dataloaders\n",
    "In the implementations we have disconnected the models and data. Hence, you should built a dataloader that fits your needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = NRMSDataLoader(\n",
    "    behaviors=df_train,\n",
    "    article_dict=article_mapping,\n",
    "    unknown_representation=\"zeros\",\n",
    "    history_column=DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "    eval_mode=False,\n",
    "    batch_size=64,\n",
    ")\n",
    "val_dataloader = NRMSDataLoader(\n",
    "    behaviors=df_validation,\n",
    "    article_dict=article_mapping,\n",
    "    unknown_representation=\"zeros\",\n",
    "    history_column=DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "    eval_mode=True,\n",
    "    batch_size=32,\n",
    ")\n",
    "test_dataloader = NRMSDataLoader(\n",
    "    behaviors=df_test,\n",
    "    article_dict=article_mapping,\n",
    "    unknown_representation=\"zeros\",\n",
    "    history_column=DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "    eval_mode=True,\n",
    "    batch_size=32,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-10 22:35:52.729306: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M2 Pro\n",
      "2024-05-10 22:35:52.729376: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
      "2024-05-10 22:35:52.729385: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.33 GB\n",
      "2024-05-10 22:35:52.729527: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-05-10 22:35:52.730806: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "2024-05-10 22:35:54.774893: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-05-10 22:35:54.880790: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node Adam/AssignAddVariableOp_14.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - ETA: 0s - loss: 1.6094"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = \"NRMS\"\n",
    "LOG_DIR = f\"../runs/{MODEL_NAME}\"\n",
    "MODEL_WEIGHTS = f\"../runs/data/state_dict/{MODEL_NAME}/weights\"\n",
    "\n",
    "# CALLBACKS\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=LOG_DIR, histogram_freq=1)\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=2)\n",
    "modelcheckpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=MODEL_WEIGHTS, save_best_only=True, save_weights_only=True, verbose=1\n",
    ")\n",
    "\n",
    "hparams_nrms.history_size = HISTORY_SIZE\n",
    "model = NRMSModel(\n",
    "    hparams=hparams_nrms,\n",
    "    word2vec_embedding=word2vec_embedding,\n",
    "    seed=42,\n",
    ")\n",
    "hist = model.model.fit(\n",
    "    train_dataloader,\n",
    "    validation_data=val_dataloader,\n",
    "    epochs=1,\n",
    "    callbacks=[tensorboard_callback, early_stopping, modelcheckpoint],\n",
    ")\n",
    "model.model.load_weights(filepath=MODEL_WEIGHTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example how to compute some metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 2s 572ms/step\n"
     ]
    }
   ],
   "source": [
    "pred_validation = model.scorer.predict(val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 7)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>user_id</th><th>article_id_fixed</th><th>article_ids_inview</th><th>article_ids_clicked</th><th>labels</th><th>scores</th><th>is_known_user</th></tr><tr><td>u32</td><td>list[i32]</td><td>list[i32]</td><td>list[i32]</td><td>list[i8]</td><td>list[f64]</td><td>bool</td></tr></thead><tbody><tr><td>909106</td><td>[9779498, 9779737, … 9779747]</td><td>[9784591, 9784044, … 9784696]</td><td>[9784679]</td><td>[0, 0, … 0]</td><td>[0.500626, 0.499298, … 0.499624]</td><td>false</td></tr><tr><td>483450</td><td>[9777190, 9777704, … 9776967]</td><td>[9789810, 9446756, … 9428643]</td><td>[9790475]</td><td>[0, 0, … 0]</td><td>[0.49968, 0.500049, … 0.499711]</td><td>false</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2, 7)\n",
       "┌─────────┬──────────────┬──────────────┬──────────────┬─────────────┬──────────────┬──────────────┐\n",
       "│ user_id ┆ article_id_f ┆ article_ids_ ┆ article_ids_ ┆ labels      ┆ scores       ┆ is_known_use │\n",
       "│ ---     ┆ ixed         ┆ inview       ┆ clicked      ┆ ---         ┆ ---          ┆ r            │\n",
       "│ u32     ┆ ---          ┆ ---          ┆ ---          ┆ list[i8]    ┆ list[f64]    ┆ ---          │\n",
       "│         ┆ list[i32]    ┆ list[i32]    ┆ list[i32]    ┆             ┆              ┆ bool         │\n",
       "╞═════════╪══════════════╪══════════════╪══════════════╪═════════════╪══════════════╪══════════════╡\n",
       "│ 909106  ┆ [9779498,    ┆ [9784591,    ┆ [9784679]    ┆ [0, 0, … 0] ┆ [0.500626,   ┆ false        │\n",
       "│         ┆ 9779737, …   ┆ 9784044, …   ┆              ┆             ┆ 0.499298, …  ┆              │\n",
       "│         ┆ 9779747]     ┆ 9784696]     ┆              ┆             ┆ 0.499624]    ┆              │\n",
       "│ 483450  ┆ [9777190,    ┆ [9789810,    ┆ [9790475]    ┆ [0, 0, … 0] ┆ [0.49968,    ┆ false        │\n",
       "│         ┆ 9777704, …   ┆ 9446756, …   ┆              ┆             ┆ 0.500049, …  ┆              │\n",
       "│         ┆ 9776967]     ┆ 9428643]     ┆              ┆             ┆ 0.499711]    ┆              │\n",
       "└─────────┴──────────────┴──────────────┴──────────────┴─────────────┴──────────────┴──────────────┘"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_validation = add_prediction_scores(df_validation, pred_validation.tolist()).pipe(\n",
    "    add_known_user_column, known_users=df_train[DEFAULT_USER_COL]\n",
    ")\n",
    "df_validation.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MetricEvaluator class>: \n",
       " {\n",
       "    \"auc\": 0.4684587424610308,\n",
       "    \"mrr\": 0.3048188440128843,\n",
       "    \"ndcg@5\": 0.3337379229627095,\n",
       "    \"ndcg@10\": 0.41919724747438886\n",
       "}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ebrec.evaluation import MetricEvaluator, AucScore, NdcgScore, MrrScore\n",
    "\n",
    "metrics = MetricEvaluator(\n",
    "    labels=df_validation[\"labels\"].to_list(),\n",
    "    predictions=df_validation[\"scores\"].to_list(),\n",
    "    metric_functions=[AucScore(), MrrScore(), NdcgScore(k=5), NdcgScore(k=10)],\n",
    ")\n",
    "metrics.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (32,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m pred_test \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscorer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_dataloader\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.asdf/installs/python/3.11.9/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.asdf/installs/python/3.11.9/lib/python3.11/site-packages/ebrec/models/newsrec/dataloader.py:99\u001b[0m, in \u001b[0;36mNRMSDataLoader.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     97\u001b[0m batch_y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(batch_y\u001b[38;5;241m.\u001b[39mexplode()\u001b[38;5;241m.\u001b[39mto_list())\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     98\u001b[0m \u001b[38;5;66;03m# =>\u001b[39;00m\n\u001b[0;32m---> 99\u001b[0m his_input_title \u001b[38;5;241m=\u001b[39m \u001b[43mrepeat_by_list_values_from_matrix\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_X\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhistory_column\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmatrix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlookup_article_matrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrepeats\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepeats\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;66;03m# =>\u001b[39;00m\n\u001b[1;32m    105\u001b[0m pred_input_title \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlookup_article_matrix[\n\u001b[1;32m    106\u001b[0m     batch_X[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minview_col]\u001b[38;5;241m.\u001b[39mexplode()\u001b[38;5;241m.\u001b[39mto_list()\n\u001b[1;32m    107\u001b[0m ]\n",
      "File \u001b[0;32m~/.asdf/installs/python/3.11.9/lib/python3.11/site-packages/ebrec/utils/_python.py:388\u001b[0m, in \u001b[0;36mrepeat_by_list_values_from_matrix\u001b[0;34m(input_array, matrix, repeats)\u001b[0m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrepeat_by_list_values_from_matrix\u001b[39m(\n\u001b[1;32m    371\u001b[0m     input_array: np\u001b[38;5;241m.\u001b[39marray,\n\u001b[1;32m    372\u001b[0m     matrix: np\u001b[38;5;241m.\u001b[39marray,\n\u001b[1;32m    373\u001b[0m     repeats: np\u001b[38;5;241m.\u001b[39marray,\n\u001b[1;32m    374\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39marray:\n\u001b[1;32m    375\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    376\u001b[0m \u001b[38;5;124;03m    Example:\u001b[39;00m\n\u001b[1;32m    377\u001b[0m \u001b[38;5;124;03m        >>> input = np.array([[1, 0], [0, 0]])\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    386\u001b[0m \u001b[38;5;124;03m                    [ 7,  8,  9]]])\u001b[39;00m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 388\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mrepeat(\u001b[43mmatrix\u001b[49m\u001b[43m[\u001b[49m\u001b[43minput_array\u001b[49m\u001b[43m]\u001b[49m, repeats\u001b[38;5;241m=\u001b[39mrepeats, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (32,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "pred_test = model.scorer.predict(test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pred_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mpred_test\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pred_test' is not defined"
     ]
    }
   ],
   "source": [
    "pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
